#Parameters
movie_path = None
output_filename = None














import bokeh.plotting as bpl
import cv2
import datetime
import glob
import holoviews as hv
from IPython import get_ipython
import logging
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import psutil
from pathlib import Path

try:
    cv2.setNumThreads(0)
except():
    pass

try:
    if __IPYTHON__:
        get_ipython().run_line_magic('load_ext', 'autoreload')
        get_ipython().run_line_magic('autoreload', '2')
except NameError:
    pass

import caiman as cm
from caiman.motion_correction import MotionCorrect
from caiman.source_extraction.cnmf import cnmf, params
from caiman.utils.utils import download_demo
from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour
from caiman.utils.visualization import view_quilt

bpl.output_notebook()
hv.notebook_extension('bokeh')


# set up logging
logging.basicConfig(format="{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}",
                    filename=None, 
                    level=logging.WARNING, style="{") #logging level can be DEBUG, INFO, WARNING, ERROR, CRITICAL

# set env variables 
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["VECLIB_MAXIMUM_THREADS"] = "1"





# press q to close
movie_orig = cm.load(movie_path) 
downsampling_ratio = 0.2  # subsample 5x
movie_orig.resize(fz=downsampling_ratio).play(gain=1.3,
                                              q_max=99.5, 
                                              fr=30,
                                              plot_text=True,
                                              magnification=2,
                                              do_loop=False,
                                              backend='opencv')


max_projection_orig = np.max(movie_orig, axis=0)
correlation_image_orig = cm.local_correlations(movie_orig, swap_dim=False)
correlation_image_orig[np.isnan(correlation_image_orig)] = 0 # get rid of NaNs, if they exist


f, (ax_max, ax_corr) = plt.subplots(1,2,figsize=(6,3))
ax_max.imshow(max_projection_orig, 
              cmap='viridis',
              vmin=np.percentile(np.ravel(max_projection_orig),50), 
              vmax=np.percentile(np.ravel(max_projection_orig),99.5));
ax_max.set_title("Max Projection Orig", fontsize=12);

ax_corr.imshow(correlation_image_orig, 
               cmap='viridis', 
               vmin=np.percentile(np.ravel(correlation_image_orig),50), 
               vmax=np.percentile(np.ravel(correlation_image_orig),99.5));
ax_corr.set_title('Correlation Image Orig', fontsize=12);








#set dimensions of the video you want to analyze in pixels here
dimensions = (490,490) #[default from video used in testing: (490,490)]

# general dataset-dependent parameters
fr = 1.5895                 # imaging rate in frames per second [default: 1.28 for the file used in initial testing]
decay_time = 20             # length of a typical transient in seconds [default: 20]
dxy = (0.2635765, 0.2635765)# spatial resolution in x and y in (um per pixel) [default: (0.2635765, 0.2635765)]

# motion correction parameters [I haven't tested different values for these]
strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels [default: (48, 48)]
overlaps = (24, 24)         # overlap between patches (width of patch = strides+overlaps) [default: (24, 24)]
max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels) [default: (6,6)]
max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts [default: 3]
pw_rigid = True             # flag for performing non-rigid motion correction [default: True]

# CNMF parameters for source extraction and deconvolution
p = 1                       # order of the autoregressive system [default: 1] {from caiman documentation: (set p=2 if there is visible rise time in data)}
gnb = 2                     # number of global background components (set to 1 or 2) [default: 2]
merge_thr = 0.85            # merging threshold, max correlation allowed [default: 0.85]
bas_nonneg = True           # enforce nonnegativity constraint on calcium traces (technically on baseline) [default: True]
rf = 70                     # half-size of the patches in pixels (patch width is rf*2 + 1) [default: 70]
stride_cnmf = rf            # amount of overlap between the patches in pixels (overlap is stride_cnmf+1) [default: stride_cnmf = rf]
K = 20                      # number of maximum expected components per patch [default: 20]
gSig = np.array([10, 10])   # expected half-width of neurons in pixels (Gaussian kernel standard deviation) [default: np.array([10, 10])]
gSiz = 2*gSig + 1           # Gaussian kernel width and hight [default: 2*gSig + 1]
method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data see demo_dendritic.ipynb) [default: 'greedy_roi']
ssub = 1                    # spatial subsampling during initialization [default: 1]
tsub = 1                    # temporal subsampling during intialization [default: 1]

# parameters for component evaluation
min_SNR = 2.0               # signal to noise ratio for accepting a component [default: 2.0]
rval_thr = 0.85             # space correlation threshold for accepting a component [default: 0.85]
cnn_thr = 0.99              # threshold for CNN based classifier [default: 0.99]
cnn_lowest = 0.1            # neurons with cnn probability lower than this value are rejected [default: 0.1]

# uncategorized parameters
rolling_sum = True #[default: True]
only_init = True #[default: True]
use_cnn = False #keep this always set to False. cnn does not work with our data because it was trained on spherical neurons


parameter_dict = {'fnames': movie_path,
                  'fr': fr,
                  'dxy': dxy,
                  'decay_time': decay_time,
                  'strides': strides,
                  'overlaps': overlaps,
                  'max_shifts': max_shifts,
                  'max_deviation_rigid': max_deviation_rigid,
                  'pw_rigid': pw_rigid,
                  'p': p,
                  'nb': gnb,
                  'rf': rf,
                  'K': K, 
                  'gSig': gSig,
                  'gSiz': gSiz,
                  'stride': stride_cnmf,
                  'method_init': method_init,
                  'rolling_sum': rolling_sum,
                  'only_init': only_init,
                  'ssub': ssub,
                  'tsub': tsub,
                  'merge_thr': merge_thr, 
                  'bas_nonneg': bas_nonneg,
                  'min_SNR': min_SNR,
                  'rval_thr': rval_thr,
                  'use_cnn': use_cnn,
                  'min_cnn_thr': cnn_thr,
                  'cnn_lowest': cnn_lowest}

parameters = params.CNMFParams(params_dict=parameter_dict) # CNMFParams is the parameters class








print(f"You have {psutil.cpu_count()} CPUs available in your current environment")
num_processors_to_use = None #default: None





if 'cluster' in locals():  # 'locals' contains list of current local variables
    print('Closing previous cluster')
    cm.stop_server(dview=cluster)
print("Setting up new cluster")
_, cluster, n_processes = cm.cluster.setup_cluster(backend='multiprocessing', 
                                                   n_processes=num_processors_to_use, 
                                                   ignore_preexisting=False)
print(f"Successfully initilialized multicore processing with a pool of {n_processes} CPU cores")











mot_correct = MotionCorrect(movie_path, dview=cluster, **parameters.motion)


%%time
#%% Run piecewise-rigid motion correction using NoRMCorre
mot_correct.motion_correct(save_movie=True);





#%% compare with original movie  : press q to quit
movie_orig = cm.load(movie_path) # in case it was not loaded earlier
movie_corrected = cm.load(mot_correct.mmap_file) # load motion corrected movie
ds_ratio = 0.2
cm.concatenate([movie_orig.resize(1, 1, ds_ratio) - mot_correct.min_mov*mot_correct.nonneg_movie,
                movie_corrected.resize(1, 1, ds_ratio)], 
                axis=2).play(fr=30, 
                             gain=2, 
                             magnification=2) 


max_projection = np.max(movie_corrected, axis=0)
correlation_image = cm.local_correlations(movie_corrected, swap_dim=False)
correlation_image[np.isnan(correlation_image)] = 0 # get rid of NaNs, if they exist


f, ((ax_max_orig, ax_max), (ax_corr_orig, ax_corr)) = plt.subplots(2,2,figsize=(6,6), sharex=True, sharey=True)
# plot max projection
ax_max_orig.imshow(max_projection_orig, 
                   cmap='viridis', 
                   vmin=np.percentile(np.ravel(max_projection_orig),50), 
                   vmax=np.percentile(np.ravel(max_projection_orig),99.5));
ax_max_orig.set_title("Max Projection: Orig", fontsize=12);
ax_max.imshow(max_projection, 
              cmap='viridis', 
              vmin=np.percentile(np.ravel(max_projection),50), 
              vmax=np.percentile(np.ravel(max_projection),99.5));
ax_max.set_title("Max Projection: Corrected", fontsize=12);

# plot correlation image
ax_corr_orig.imshow(correlation_image_orig, 
                    cmap='viridis', 
                   vmin=np.percentile(np.ravel(correlation_image_orig),50), 
                   vmax=np.percentile(np.ravel(correlation_image_orig),99.5));
ax_corr_orig.set_title('Correlation Im: Orig', fontsize=12);
ax_corr.imshow(correlation_image, 
               cmap='viridis', 
               vmin=np.percentile(np.ravel(correlation_image),50), 
               vmax=np.percentile(np.ravel(correlation_image),99.5));
ax_corr.set_title('Correlation Im: Corrected', fontsize=12);

plt.tight_layout()





border_to_0 = 0 if mot_correct.border_nan == 'copy' else mot_correct.border_to_0 # trim border against NaNs
mc_memmapped_fname = cm.save_memmap(mot_correct.mmap_file, 
                                        base_name='memmap_', 
                                        order='C',
                                        border_to_0=border_to_0,  # exclude borders, if that was done
                                        dview=cluster)

Yr, dims, num_frames = cm.load_memmap(mc_memmapped_fname)
images = np.reshape(Yr.T, [num_frames] + list(dims), order='F') #reshape frames in standard 3d format (T x X x Y)





cm.stop_server(dview=cluster)
_, cluster, n_processes = cm.cluster.setup_cluster(backend='multiprocessing', 
                                                   n_processes=num_processors_to_use, 
                                                   single_thread=False)











cnmf_model = cnmf.CNMF(n_processes, 
                       params=parameters, 
                       dview=cluster)





# calculate stride and overlap from parameters
cnmf_patch_width = cnmf_model.params.patch['rf']*2 + 1
cnmf_patch_overlap = cnmf_model.params.patch['stride'] + 1
cnmf_patch_stride = cnmf_patch_width - cnmf_patch_overlap
print(f'Patch width: {cnmf_patch_width} , Stride: {cnmf_patch_stride}, Overlap: {cnmf_patch_overlap}');

# plot the patches
patch_ax = view_quilt(correlation_image, 
                      cnmf_patch_stride, 
                      cnmf_patch_overlap, 
                      vmin=np.percentile(np.ravel(correlation_image),50), 
                      vmax=np.percentile(np.ravel(correlation_image),99.5),
                      figsize=(4,4));
patch_ax.set_title(f'CNMF Patches Width {cnmf_patch_width}, Overlap {cnmf_patch_overlap}');





%%time
cnmf_fit = cnmf_model.fit(images)





cnmf_fit.estimates.plot_contours_nb(img=correlation_image);





%%time
cnmf_refit = cnmf_fit.refit(images, dview=cluster)





cnmf_refit.estimates.plot_contours_nb(img=correlation_image);





# see shape of A and C
cnmf_refit.estimates.A.shape, cnmf_refit.estimates.C.shape














print("Thresholds to be used for evaluate_components()")
print(f"min_SNR = {cnmf_refit.params.quality['min_SNR']}")
print(f"rval_thr = {cnmf_refit.params.quality['rval_thr']}")
print(f"min_cnn_thr = {cnmf_refit.params.quality['min_cnn_thr']}")





cnmf_refit.estimates.evaluate_components(images, cnmf_refit.params, dview=cluster);





print(f"Num accepted/rejected: {len(cnmf_refit.estimates.idx_components)}, {len(cnmf_refit.estimates.idx_components_bad)}")








cnmf_refit.estimates.plot_contours_nb(img=correlation_image, 
                                      idx=cnmf_refit.estimates.idx_components);





# view accepted components
cnmf_refit.estimates.nb_view_components(img=correlation_image, 
                                        idx=cnmf_refit.estimates.idx_components,
                                        cmap='gray',
                                        denoised_color='red');





# rejected components
if len(cnmf_refit.estimates.idx_components_bad) > 0:
    cnmf_refit.estimates.nb_view_components(img=correlation_image, 
                                            idx=cnmf_refit.estimates.idx_components_bad, 
                                            cmap='gray',
                                            denoised_color='red')
else:
    print("No components were rejected.")








#do not delete this portion of code. I don't know if I still need it, but I'm not touching it
idx_accepted = cnmf_refit.estimates.idx_components
all_contour_coords = [cnmf_refit.estimates.coordinates[idx]['coordinates'] for idx in idx_accepted]








if cnmf_refit.estimates.F_dff is None:
    print('Calculating estimates.F_dff')
    cnmf_refit.estimates.detrend_df_f(quantileMin=8, 
                                      frames_window=250,
                                      flag_auto=False,
                                      use_residuals=False);  
else:
    print("estimates.F_dff already defined")





frame_rate = cnmf_refit.params.data['fr']
frame_pd = 1/frame_rate
frame_times = np.linspace(0, num_frames*frame_pd, num_frames);


# plot F_dff
idx_to_plot = 6
idx_accepted = cnmf_refit.estimates.idx_components
component_number = idx_accepted[idx_to_plot]
f, ax = plt.subplots(figsize=(7,2))
ax.plot(frame_times, 
        cnmf_refit.estimates.F_dff[component_number, :], 
        linewidth=0.5,
        color='k');
ax.set_xlabel('Time (s)')
ax.set_ylabel('$\Delta F/F$')
ax.set_title(f"$\Delta F/F$ for unit {component_number}");
plt.tight_layout()








cnmf_refit.estimates.select_components(use_object=True);








cnmf_refit.estimates.nb_view_components(img=correlation_image,
                                        idx=None,
                                        thr=0.99,
                                        denoised_color='red',
                                        cmap='viridis',
                                        );
#if the destructive process that preceeds this is commented out, the bad components won't be removed


cnmf_refit.estimates.plot_contours_nb(img=correlation_image,
                                     idx=cnmf_refit.estimates.idx_components,
                                     cmap='viridis');





#if the image scale is messed up, you need to set the dimensions of your video. Origionally set to 490x490
dimensions = dimensions

#pathing for where the file gets saved
pretty_save_path = output_filename + 'pretty_plot.png'

#I just chose as many colors as I needed to make sure there weren't too many overlaps
colors = ['xkcd:red','xkcd:purple','xkcd:green',
          'xkcd:blue','xkcd:pink','xkcd:orange',
          'xkcd:yellow','xkcd:cyan','xkcd:wine',
          'xkcd:leaf','xkcd:green yellow','xkcd:orange red',
         'xkcd:butter','xkcd:pea soup']
fig=plt.figure(frameon=False,figsize=dimensions,dpi=1)
x=0
while x < len(idx_accepted):
    idx_to_plot = x
    component_number = idx_accepted[idx_to_plot]
    component_contour = all_contour_coords[idx_to_plot]
    component_footprint = np.reshape(cnmf_refit.estimates.A[:, idx_to_plot].toarray(), dims, order='F')
    plt.plot(component_contour[:, 0], 
             component_contour[:, 1], 
             color=colors[x % len(colors)], 
             linewidth=1,
            alpha = 0.50)
    plt.fill(component_contour[:, 0], 
             component_contour[:, 1], 
             color=colors[x % len(colors)], 
             linewidth=0.5,
            alpha = 0.25)
    x= x+1
else:
    plt.axis('off')
    plt.imshow(correlation_image,cmap='gray');
#don't get rid of any of the stuff here, need it to stop plt.savefig from messing up the image resolution
    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, 
            hspace = 0, wspace = 0)
    plt.margins(0,0)
    plt.gca().xaxis.set_major_locator(plt.NullLocator())
    plt.gca().yaxis.set_major_locator(plt.NullLocator())
    plt.savefig(pretty_save_path,bbox_inches=None,pad_inches=None,dpi='figure') 

colors = ['xkcd:purple','xkcd:wine',
          'xkcd:blue','xkcd:pink','xkcd:cyan',
          'xkcd:yellow','xkcd:orange','xkcd:green',
          'xkcd:leaf','xkcd:green yellow','xkcd:orange red',
         'xkcd:butter','xkcd:red']
fig=plt.figure(frameon=False,figsize=dimensions,dpi=1)
x=0
while x < len(idx_accepted):
    idx_to_plot = x
    component_number = idx_accepted[idx_to_plot]
    component_contour = all_contour_coords[idx_to_plot]
    component_footprint = np.reshape(cnmf_refit.estimates.A[:, idx_to_plot].toarray(), dims, order='F')
    plt.plot(component_contour[:, 0], 
             component_contour[:, 1], 
             color=colors[x % len(colors)], 
             linewidth=1,
            alpha = 0.50)
    plt.fill(component_contour[:, 0], 
             component_contour[:, 1], 
             color=colors[x % len(colors)], 
             linewidth=0.5,
            alpha = 0.25)
    x= x+1
else:
    plt.axis('off')
    plt.imshow(correlation_image,cmap='gray');
#don't get rid of any of the stuff here, need it to stop plt.savefig from messing up the image resolution
    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, 
            hspace = 0, wspace = 0)
    plt.margins(0,0)
    plt.gca().xaxis.set_major_locator(plt.NullLocator())
    plt.gca().yaxis.set_major_locator(plt.NullLocator())





#exporting a text file containing the parameters used for data analysis
import csv
output_file1 = output_filename + 'settings_list.txt'
csv_file = output_file1
csv_columns = ['fnames',
                  'fr',
                  'dxy',
                  'decay_time',
                  'strides',
                  'overlaps',
                  'max_shifts',
                  'max_deviation_rigid',
                  'pw_rigid',
                  'p',
                  'nb',
                  'rf',
                  'K', 
                  'gSig',
                  'gSiz',
                  'stride',
                  'method_init',
                  'rolling_sum',
                  'only_init',
                  'ssub',
                  'tsub',
                  'merge_thr',
                  'bas_nonneg',
                  'min_SNR',
                  'rval_thr',
                  'use_cnn',
                  'min_cnn_thr',
                  'cnn_lowest']
params_dict = {'fnames': movie_path,
                  'fr': fr,
                  'dxy': dxy,
                  'decay_time': decay_time,
                  'strides': strides,
                  'overlaps': overlaps,
                  'max_shifts': max_shifts,
                  'max_deviation_rigid': max_deviation_rigid,
                  'pw_rigid': pw_rigid,
                  'p': p,
                  'nb': gnb,
                  'rf': rf,
                  'K': K, 
                  'gSig': gSig,
                  'gSiz': gSiz,
                  'stride': stride_cnmf,
                  'method_init': method_init,
                  'rolling_sum': rolling_sum,
                  'only_init': only_init,
                  'ssub': ssub,
                  'tsub': tsub,
                  'merge_thr': merge_thr, 
                  'bas_nonneg': bas_nonneg,
                  'min_SNR': min_SNR,
                  'rval_thr': rval_thr,
                  'use_cnn': use_cnn,
                  'min_cnn_thr': cnn_thr,
                  'cnn_lowest': cnn_lowest}
index=0
# Open the file in write mode ('w') with the full path
with open(output_file1, 'w') as f:
    f.write('Analysis settings used')  # Write header to the file
    for item in csv_columns:
        line = f"{item}\t{params_dict[csv_columns[index]]}\n"
        f.write(line)  # Write each line to the file
        index = index + 1


print(f"Settings used saved to '{output_file1}'")


#saving calcium traces
data_to_save = np.vstack((frame_times, cnmf_refit.estimates.C)).T  # Transpose so time series are in columns
save_df = pd.DataFrame(data_to_save)
save_df.rename(columns={0:'time'}, inplace=True)
# check out the dataframe
save_df.head()
c_save_path = output_filename + 'C_traces.csv'
save_df.to_csv(c_save_path, index=False)
print(f"Saved estimates.C to {c_save_path}")


#saving normalized transmittance
data_to_save = np.vstack((frame_times, cnmf_refit.estimates.F_dff)).T  # Transpose so time series are in columns
save_df = pd.DataFrame(data_to_save)
save_df.rename(columns={0:'time(s)'}, inplace=True)
# Insert an empty column at the first position
save_df.insert(0, '', np.nan)
# check out the dataframe
save_df.head()

# Rename the remaining columns to Roi1, Roi2, etc.
for i in range(1, len(save_df.columns) - 1):  # start from 1 to skip 'Empty Column'
    save_df.rename(columns={i: f'Roi{i}'}, inplace=True)


c_save_path = output_filename + 'F_dff.txt'
save_df.to_csv(c_save_path, index=False)
print(f"Saved estimates.F_dff to {c_save_path}")



#saving spike trains
data_to_save = np.vstack((frame_times, cnmf_refit.estimates.S)).T  # Transpose so time series are in columns
save_df = pd.DataFrame(data_to_save)
save_df.rename(columns={0:'time'}, inplace=True)
# check out the dataframe
save_df.head()

c_save_path = output_filename + 'S.csv'
save_df.to_csv(c_save_path, index=False)
print(f"Saved estimates.S to {c_save_path}")





print(idx_accepted)


#assembling an array for the ROI centers
centers = np.array([['neuron_id','x','y']])
for item in cnmf_refit.estimates.coordinates:
    #insert stuff for time of peak response
    CoM_coords = item['CoM']
    line = np.array([[item['neuron_id'],CoM_coords[1],CoM_coords[0]]])
    centers = np.concatenate((centers,line),axis=0)


## Set background transmittance threshold  [default used in testing: 0.001]
#[omit any spike activity from cnmf_refit.estimates.S with normalized intensity at or below this threshold]
#this was done because of a large number of near-zero values that are likely due to accumulated arithmatic error
spike_thr = 0.001

#make csv file with all spikes
output_file = output_filename + 'S_spikes.txt'


#clear and define needed variables
test_roi = 0
roi_num = 0
s_start = 0
s_dur = 0
float_sum=0
roi_label=0
roi_x=0
roi_y=0
starttime=0
hightime=0
highamp=0


#assembling an array for the ROI centers
centers = np.array([['neuron_id','x','y']])
for item in cnmf_refit.estimates.coordinates:
    #insert stuff for time of peak response
    CoM_coords = item['CoM']
    line = np.array([[item['neuron_id'],CoM_coords[1],CoM_coords[0]]])
    centers = np.concatenate((centers,line),axis=0)



#start of spike extraction
with open(output_file, 'w') as f:
    f.write('ROI#\t spike #\t CoM x(px)\t CoM y(px)\t start of spike(frames from start of video)\t time at max spike amplitude(ffsov)\t duration(frames)\t max amplitude\t sum of amplitudes\n')# Write header to the file
    while roi_num < len(cnmf_refit.estimates.S):
        test_roi = np.vstack((frame_times, cnmf_refit.estimates.S[roi_num])).T;
        #select one ROI at a time and transpose so data is in format of [frame time, normalized intensity]
        l=0
        spike_idx=0
        roi_label=roi_num+1 #set value for ROI that matches other caiman outputs (columns in c_traces for example)
        roi_x=centers[roi_num+1][1] #set x value of the center for the ROI analyzed
        roi_y=centers[roi_num+1][2] #set y value of the CoM for ROI being analyzed
        while l < len(test_roi): #start loop => will scan through data extracted by Caiman from video frame by frame
            if test_roi[l][1]>spike_thr: #if amplitude is above threshold, start spike math loops
                spike_idx=spike_idx+1 #set identifier for detected spike
                s_start=l #set start frame of detected spike
                while test_roi[l][1]>spike_thr:
                    float_sum=float_sum+test_roi[l][1] #rolling sum of all amplitudes during spike
                    if test_roi[l][1]>highamp: #find point of highest activity 
                        highamp=test_roi[l][1] #set activity value for peak
                        hightime=l #set time at peak in frames
                    l=l+1 #advance 1 frame
                    if l == len(test_roi): break #breaks this loop if at end of movie
                else: 
                    #s_dur = test_roi[l][0]-test_roi[s_start][0] #for seconds instead of frames
                    s_dur = l-s_start; #for frames instead of seconds
                    ##starttime=test_roi[s_start][0] #for seconds instead of frames
                    starttime=s_start #for frames instead of seconds
                    ##hightime=test_roi[hightime][0] #convert time of peak amplitude to seconds
                    line=f"{roi_label}\t{spike_idx}\t{roi_x}\t{roi_y}\t{starttime}\t{hightime}\t{s_dur}\t{highamp}\t{float_sum}\n" #assemble the components extracted earlier in the loop
                    f.write(line) #record components to file
                    #print(line); #prints spike summary values for user to check in the next cell
                    float_sum=0; #reset sum
                    highamp=0; #reset highest amplitude within spike
                    hightime=0; #reset time at highest amplitude within spike
                    l = l+1; #advance one frame before starting to check for activity
                    if l == len(test_roi): break #if at the end of the video, break this loop
            else:
                l=l+1
                if l == len(test_roi): break
        roi_num = roi_num+1


print(f"Spiketrain summary data saved to '{output_file}'")


### Spike extraction using Delta F/F0 values
## Set background transmittance threshold [default 0. Will have errors if below 0]
#[omit any spike activity from cnmf_refit.estimates.F_dff with normalized intensity at or below this threshold]
#this was done because of a large number of near-zero values that are likely due to accumulated arithmatic error
spike_thr = 0

#make csv file with all spikes
output_file = output_filename + 'dela_F_spikes.txt'


#clear and define needed variables
test_roi = 0
roi_num = 0
s_start = 0
s_dur = 0
float_sum=0
roi_label=0
roi_x=0
roi_y=0
starttime=0
hightime=0
highamp=0


#assembling an array for the ROI centers
centers = np.array([['neuron_id','x','y']])
for item in cnmf_refit.estimates.coordinates:
    #insert stuff for time of peak response
    CoM_coords = item['CoM']
    line = np.array([[item['neuron_id'],CoM_coords[1],CoM_coords[0]]])
    centers = np.concatenate((centers,line),axis=0)

#start of spike extraction
with open(output_file, 'w') as f:
    f.write('ROI#\t spike #\t CoM x(px)\t CoM y(px)\t start of spike(frames from start of video)\t time at max spike amplitude(ffsov)\t duration(frames)\t max amplitude\t sum of amplitudes\n')# Write header to the file
    print('ROI#\t spike #\t CoM x(px)\t CoM y(px)\t start of spike(frames from start of video)\t time at max spike amplitude(ffsov)\t duration(frames)\t max amplitude\t sum of amplitudes\n')
    while roi_num < len(cnmf_refit.estimates.F_dff):
        test_roi = np.vstack((frame_times, cnmf_refit.estimates.F_dff[roi_num])).T;
        #select one ROI at a time and transpose so data is in format of [frame time, normalized intensity]
        l=0
        spike_idx=0
        roi_label=roi_num+1 #set value for ROI that matches other caiman outputs (columns in c_traces for example)
        roi_x=centers[roi_num+1][1] #set x value of the center for the ROI analyzed
        roi_y=centers[roi_num+1][2] #set y value of the CoM for ROI being analyzed
        while l < len(test_roi): #start loop => will scan through data extracted by Caiman from video frame by frame
            if test_roi[l][1]>spike_thr: #if amplitude is above threshold, start spike math loops
                spike_idx=spike_idx+1 #set identifier for detected spike
                s_start=l #set start frame of detected spike
                while test_roi[l][1]>spike_thr:
                    float_sum=float_sum+test_roi[l][1] #rolling sum of all amplitudes during spike
                    if test_roi[l][1]>highamp: #find point of highest activity 
                        highamp=test_roi[l][1] #set activity value for peak
                        hightime=l #set time at peak in frames
                    l=l+1 #advance 1 frame
                    if l == len(test_roi): break #breaks this loop if at end of movie
                else: 
                    #s_dur = test_roi[l][0]-test_roi[s_start][0] #for seconds instead of frames
                    s_dur = l-s_start; #for frames instead of seconds
                    ##starttime=test_roi[s_start][0] #for seconds instead of frames
                    starttime=s_start #for frames instead of seconds
                    ##hightime=test_roi[hightime][0] #convert time of peak amplitude to seconds
                    line=f"{roi_label}\t{spike_idx}\t{roi_x}\t{roi_y}\t{starttime}\t{hightime}\t{s_dur}\t{highamp}\t{float_sum}\n" #assemble the components extracted earlier in the loop
                    f.write(line) #record components to file
                    #print(line); #prints spike summary values for user to check in the next cell
                    float_sum=0; #reset sum
                    highamp=0; #reset highest amplitude within spike
                    hightime=0; #reset time at highest amplitude within spike
                    l = l+1; #advance one frame before starting to check for activity
                    if l == len(test_roi): break #if at the end of the video, break this loop
            else:
                l=l+1
                if l == len(test_roi): break
        roi_num = roi_num+1


print(f"Delta F spikes summary data saved to '{output_file}'")


### Spike extraction using Delta F/F0 values
## Set background transmittance threshold [default 0. Will have errors if below 0]
#[omit any spike activity from cnmf_refit.estimates.F_dff with normalized intensity at or below this threshold]
#this was done because of a large number of near-zero values that are likely due to accumulated arithmatic error
spike_thr = 0

#make csv file with all spikes
output_file = output_filename + 'RAAIM_DF_UnverifiedSpread.txt'


#clear and define needed variables
test_roi = 0
roi_num = 0
s_start = 0
s_dur = 0
float_sum=0
roi_label=0
roi_x=0
roi_y=0
starttime=0
hightime=0
highamp=0
S_AUC=0
decaytime=0
s_atk=0
s_dky=0
pxspread=0

#assembling an array for the ROI centers
centers = np.array([['neuron_id','x','y']])
for item in cnmf_refit.estimates.coordinates:
    #insert stuff for time of peak response
    CoM_coords = item['CoM']
    line = np.array([[item['neuron_id'],CoM_coords[1],CoM_coords[0]]])
    centers = np.concatenate((centers,line),axis=0)

#start of spike extraction
with open(output_file, 'w') as f:
    f.write('ROI\tX\tY\tAmp(F/F0)\tTime(s)\tduration(s)\tattack(s)\tdecay(s)\tA.U.C.(F*s/F0)\tSpread(pixels^2)\n')# Write header to the file
    print('ROI\tX\tY\tAmp(F/F0)\tTime(s)\tduration(s)\tattack(s)\tdecay(s)\tA.U.C.(F*s/F0)\tSpread(pixels^2)\n')
    while roi_num < len(cnmf_refit.estimates.F_dff):
        test_roi = np.vstack((frame_times, cnmf_refit.estimates.F_dff[roi_num])).T;
        #select one ROI at a time and transpose so data is in format of [frame time, normalized intensity]
        l=0
        spike_idx=0
        roi_label=roi_num+1 #set value for ROI that matches other caiman outputs (columns in c_traces for example)
        roi_x=centers[roi_num+1][1] #set x value of the center for the ROI analyzed
        roi_y=centers[roi_num+1][2] #set y value of the CoM for ROI being analyzed
        while l < len(test_roi): #start loop => will scan through data extracted by Caiman from video frame by frame
            if test_roi[l][1]>spike_thr: #if amplitude is above threshold, start spike math loops
                spike_idx=spike_idx+1 #set identifier for detected spike
                s_start=l #set start frame of detected spike
                while test_roi[l][1]>spike_thr:
                    float_sum=float_sum+test_roi[l][1] #rolling sum of all amplitudes during spike
                    if test_roi[l][1]>highamp: #find point of highest activity 
                        highamp=test_roi[l][1] #set activity value for peak
                        hightime=l #set time at peak in frames
                    l=l+1 #advance 1 frame
                    if l == len(test_roi): break #breaks this loop if at end of movie
                else: 
                    s_dur = test_roi[l][0]-test_roi[s_start][0] #for seconds instead of frames
                    starttime=test_roi[s_start][0] #for seconds instead of frames
                    s_atk=test_roi[hightime][0]-test_roi[s_start][0]
                    hightime=test_roi[hightime][0] #convert time of peak amplitude to seconds
                    S_AUC=s_dur*float_sum
                    s_dky=s_dur-s_atk
                    component_contour = all_contour_coords[roi_num]
                    pxspread=len(component_contour)
                    line=f"{roi_label}\t{roi_x}\t{roi_y}\t{highamp}\t{hightime}\t{s_dur}\t{s_atk}\t{s_dky}\t{S_AUC}\t{pxspread}\n" #assemble the components extracted earlier in the loop
                    f.write(line) #record components to file
                    print(line); #prints spike summary values for user to check in the next cell
                    float_sum=0; #reset sum
                    highamp=0; #reset highest amplitude within spike
                    hightime=0; #reset time at highest amplitude within spike
                    l = l+1; #advance one frame before starting to check for activity
                    if l == len(test_roi): break #if at the end of the video, break this loop
            else:
                l=l+1
                if l == len(test_roi): break
        roi_num = roi_num+1





#import os
#selecting directory and setting filename
output_file = output_filename + 'accepted_ROIs_list.txt'

CoM_coords = 0
# Open the file in write mode ('w') with the full path
with open(output_file, 'w') as f:
    f.write('index(neuron ID)\tX\tY\n')  # Write header to the file
    for item in cnmf_refit.estimates.coordinates:
        CoM_coords = item['CoM']
        line = f"{item['neuron_id']}\t{CoM_coords[1]}\t{CoM_coords[0]}\n"
        f.write(line)  # Write each line to the file

print(f"Data saved to '{output_file}'")












# reconstruct denoised movie
neural_activity = cnmf_refit.estimates.A @ cnmf_refit.estimates.C  # AC
background = cnmf_refit.estimates.b @ cnmf_refit.estimates.f  # bf
denoised_movie = neural_activity + background  # AC + bf

# turn into a movie object
denoised_movie = cm.movie(denoised_movie).reshape(dims + (-1,), order='F').transpose([2, 0, 1])











from caiman.base.movies import play_movie

# in case you are working from loaded data, recover the raw movie
Yr, dims, num_frames = cm.load_memmap(cnmf_refit.mmap_file)
images = np.reshape(Yr.T, [num_frames] + list(dims), order='F')


# press q to quit (can take a while to start running)
cnmf_refit.estimates.play_movie(images, 
                                q_max=99.9, 
                                gain_res=1,
                                magnification=1,
                                include_bck=True,
                                use_color=True,
                                frame_range=slice(None, None, 10),
                                thr=0); # set thr to 0.1 to see contours





save_results = True
if save_results:
    save_path = output_filename + 'output.hdf5'  # or add full/path/to/file.hdf5
    cnmf_refit.estimates.Cn = correlation_image # squirrel away correlation image with cnmf object
    cnmf_refit.save(save_path)








load_results = True
if load_results:
    save_path =  output_filename + 'output.hdf5'  # or add full/path/to/file.hdf5
    cnmf_refit = cnmf.load_CNMF(save_path, 
                                n_processes=num_processors_to_use, 
                                dview=cluster)
    correlation_image = cnmf_refit.estimates.Cn
    print(f"Successfully loaded data.")


# Example of accessing the fluorescence traces
# Load a timeseries object (example)
timeseries = load('path_to_file.h5')

# Access fluorescence traces
fluorescence_traces = timeseries.F

# Print some traces
print(fluorescence_traces[0])  # Print the first trace








cm.stop_server(dview=cluster)





# Shut down logger (otherwise will not be able to delete it)
logging.shutdown()


delete_logs = True
logging_dir = cm.paths.get_tempdir() 
if delete_logs:
    log_files = glob.glob(logging_dir + '\\demo_pipeline' + '*' + '.log')
    for log_file in log_files:
        print(f"Deleting {log_file}")
        os.remove(log_file)
else:
    print(f"If you want to inspect your logs they are in {logging_dir}")



